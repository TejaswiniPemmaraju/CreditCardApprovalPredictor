{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3890efd",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Building automatic credit card approval predictor using machine learning techniques: logisitc regression model and Xgboost classification. \n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/dataset/27/credit+approval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfdc74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79918bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 27, 'name': 'Credit Approval', 'repository_url': 'https://archive.ics.uci.edu/dataset/27/credit+approval', 'data_url': 'https://archive.ics.uci.edu/static/public/27/data.csv', 'abstract': 'This data concerns credit card applications; good mix of attributes', 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 690, 'num_features': 15, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': [], 'target_col': ['A16'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1987, 'last_updated': 'Wed Aug 23 2023', 'dataset_doi': '10.24432/C5FS30', 'creators': ['J. R. Quinlan'], 'intro_paper': None, 'additional_info': {'summary': 'This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.\\r\\n  \\r\\nThis dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'A1:\\tb, a.\\r\\nA2:\\tcontinuous.\\r\\nA3:\\tcontinuous.\\r\\nA4:\\tu, y, l, t.\\r\\nA5:\\tg, p, gg.\\r\\nA6:\\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\\r\\nA7:\\tv, h, bb, j, n, z, dd, ff, o.\\r\\nA8:\\tcontinuous.\\r\\nA9:\\tt, f.\\r\\nA10:\\tt, f.\\r\\nA11:\\tcontinuous.\\r\\nA12:\\tt, f.\\r\\nA13:\\tg, p, s.\\r\\nA14:\\tcontinuous.\\r\\nA15:\\tcontinuous.\\r\\nA16: +,-         (class attribute)', 'citation': None}}\n",
      "   name     role         type demographic description units missing_values\n",
      "0   A16   Target  Categorical        None        None  None             no\n",
      "1   A15  Feature   Continuous        None        None  None             no\n",
      "2   A14  Feature   Continuous        None        None  None            yes\n",
      "3   A13  Feature  Categorical        None        None  None             no\n",
      "4   A12  Feature  Categorical        None        None  None             no\n",
      "5   A11  Feature   Continuous        None        None  None             no\n",
      "6   A10  Feature  Categorical        None        None  None             no\n",
      "7    A9  Feature  Categorical        None        None  None             no\n",
      "8    A8  Feature   Continuous        None        None  None             no\n",
      "9    A7  Feature  Categorical        None        None  None            yes\n",
      "10   A6  Feature  Categorical        None        None  None            yes\n",
      "11   A5  Feature  Categorical        None        None  None            yes\n",
      "12   A4  Feature  Categorical        None        None  None            yes\n",
      "13   A3  Feature   Continuous        None        None  None             no\n",
      "14   A2  Feature   Continuous        None        None  None            yes\n",
      "15   A1  Feature  Categorical        None        None  None            yes\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "credit_approval = fetch_ucirepo(id=27) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = credit_approval.data.features \n",
    "y = credit_approval.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(credit_approval.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(credit_approval.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd93e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d056817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A15    A14 A13 A12  A11 A10 A9    A8 A7 A6 A5 A4     A3     A2 A1\n",
      "0    0  202.0   g   f    1   t  t  1.25  v  w  g  u  0.000  30.83  b\n",
      "1  560   43.0   g   f    6   t  t  3.04  h  q  g  u  4.460  58.67  a\n",
      "2  824  280.0   g   f    0   f  t  1.50  h  q  g  u  0.500  24.50  a\n",
      "3    3  100.0   g   t    5   t  t  3.75  v  w  g  u  1.540  27.83  b\n",
      "4    0  120.0   s   f    0   f  t  1.71  v  w  g  u  5.625  20.17  b\n",
      "  A16\n",
      "0   +\n",
      "1   +\n",
      "2   +\n",
      "3   +\n",
      "4   +\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fb96f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 A15          A14        A11          A8          A3  \\\n",
      "count     690.000000   677.000000  690.00000  690.000000  690.000000   \n",
      "mean     1017.385507   184.014771    2.40000    2.223406    4.758725   \n",
      "std      5210.102598   173.806768    4.86294    3.346513    4.978163   \n",
      "min         0.000000     0.000000    0.00000    0.000000    0.000000   \n",
      "25%         0.000000    75.000000    0.00000    0.165000    1.000000   \n",
      "50%         5.000000   160.000000    0.00000    1.000000    2.750000   \n",
      "75%       395.500000   276.000000    3.00000    2.625000    7.207500   \n",
      "max    100000.000000  2000.000000   67.00000   28.500000   28.000000   \n",
      "\n",
      "               A2  \n",
      "count  678.000000  \n",
      "mean    31.568171  \n",
      "std     11.957862  \n",
      "min     13.750000  \n",
      "25%     22.602500  \n",
      "50%     28.460000  \n",
      "75%     38.230000  \n",
      "max     80.250000  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A15     690 non-null    int64  \n",
      " 1   A14     677 non-null    float64\n",
      " 2   A13     690 non-null    object \n",
      " 3   A12     690 non-null    object \n",
      " 4   A11     690 non-null    int64  \n",
      " 5   A10     690 non-null    object \n",
      " 6   A9      690 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A7      681 non-null    object \n",
      " 9   A6      681 non-null    object \n",
      " 10  A5      684 non-null    object \n",
      " 11  A4      684 non-null    object \n",
      " 12  A3      690 non-null    float64\n",
      " 13  A2      678 non-null    float64\n",
      " 14  A1      678 non-null    object \n",
      "dtypes: float64(4), int64(2), object(9)\n",
      "memory usage: 81.0+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "cc_apps_description = X.describe()\n",
    "print(cc_apps_description)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Print DataFrame information\n",
    "cc_apps_info = X.info()\n",
    "print(cc_apps_info)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a5108f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping DriversLicense and ZipCode column as they are not as significant while predicitng credit card approvals.\n",
    "X = X.drop(columns=['A11','A13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6fc41cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = X.join(y)\n",
    "\n",
    "# Split into train and test sets\n",
    "all_train, all_test = train_test_split(all_columns, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eaa244fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There were few ? in the dataset. Replace the '?'s with NaN in the train and test sets\n",
    "all_train = all_train.replace('?', np.nan)\n",
    "all_test = all_test.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c320ef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A15     0\n",
      "A14    10\n",
      "A12     0\n",
      "A10     0\n",
      "A9      0\n",
      "A8      0\n",
      "A7      6\n",
      "A6      6\n",
      "A5      5\n",
      "A4      5\n",
      "A3      0\n",
      "A2      4\n",
      "A1      6\n",
      "A16     0\n",
      "dtype: int64\n",
      "A15    0\n",
      "A14    3\n",
      "A12    0\n",
      "A10    0\n",
      "A9     0\n",
      "A8     0\n",
      "A7     3\n",
      "A6     3\n",
      "A5     1\n",
      "A4     1\n",
      "A3     0\n",
      "A2     8\n",
      "A1     6\n",
      "A16    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for NAN values\n",
    "count_all_train = all_train.isna().sum()\n",
    "count_all_test = all_test.isna().sum()\n",
    "\n",
    "print(count_all_train)\n",
    "print(count_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b10ac7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A15    0\n",
      "A14    0\n",
      "A12    0\n",
      "A10    0\n",
      "A9     0\n",
      "A8     0\n",
      "A7     6\n",
      "A6     6\n",
      "A5     5\n",
      "A4     5\n",
      "A3     0\n",
      "A2     0\n",
      "A1     6\n",
      "A16    0\n",
      "dtype: int64\n",
      "A15    0\n",
      "A14    0\n",
      "A12    0\n",
      "A10    0\n",
      "A9     0\n",
      "A8     0\n",
      "A7     3\n",
      "A6     3\n",
      "A5     1\n",
      "A4     1\n",
      "A3     0\n",
      "A2     0\n",
      "A1     6\n",
      "A16    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Removing Nan Values in numeric columns by using mean imputation\n",
    "all_train.fillna(all_train.mean(), inplace=True)\n",
    "all_test.fillna(all_test.mean(), inplace=True)\n",
    "\n",
    "# Count the number of NaNs in the datasets and print the counts to verify\n",
    "# ... YOUR CODE FOR TASK 5 ...\n",
    "count_na_train = all_train.isna().sum()\n",
    "count_na_test = all_test.isna().sum()\n",
    "\n",
    "print(count_na_train)\n",
    "print(count_na_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "845a2062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A15    0\n",
      "A14    0\n",
      "A12    0\n",
      "A10    0\n",
      "A9     0\n",
      "A8     0\n",
      "A7     0\n",
      "A6     0\n",
      "A5     0\n",
      "A4     0\n",
      "A3     0\n",
      "A2     0\n",
      "A1     0\n",
      "A16    0\n",
      "dtype: int64\n",
      "A15    0\n",
      "A14    0\n",
      "A12    0\n",
      "A10    0\n",
      "A9     0\n",
      "A8     0\n",
      "A7     0\n",
      "A6     0\n",
      "A5     0\n",
      "A4     0\n",
      "A3     0\n",
      "A2     0\n",
      "A1     0\n",
      "A16    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Filling missing values for categorical columns with most frequently occuring value\n",
    "# Iterate over each column of X\n",
    "for col in all_train:\n",
    "    # Check if the column is of object type\n",
    "    if all_train[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        all_train[col] = all_train[col].fillna(all_train[col].value_counts().idxmax())\n",
    "        all_test[col] = all_test[col].fillna(all_train[col].value_counts().idxmax())\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify\n",
    "count_all_train = all_train.isna().sum()\n",
    "count_all_test = all_test.isna().sum()\n",
    "\n",
    "print(count_all_train)\n",
    "print(count_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9bced72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre processing\n",
    "# Convert the categorical features in the train and test sets independently\n",
    "cc_apps_train = pd.get_dummies(all_train)\n",
    "cc_apps_test = pd.get_dummies(all_test)\n",
    "\n",
    "# Reindex the columns of the test set aligning with the train set\n",
    "cc_apps_test = cc_apps_test.reindex(columns=cc_apps_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "014b37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X_train, y_train = cc_apps_train.iloc[:, :-1].values, cc_apps_train.iloc[:, [-1]].values\n",
    "X_test, y_test = cc_apps_test.iloc[:, :-1].values, cc_apps_test.iloc[:, [-1]].values\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "55c3f65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train,y_train)\n",
    "print(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ae3aca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[154,   0],\n",
       "       [  0, 191]], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_test))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a494e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "tol = [0.01, 0.001 ,0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\n",
    "param_grid = dict(tol=tol, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "18eb634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1.000000 using {'max_iter': 100, 'tol': 0.01}\n",
      "Accuracy of logistic regression classifier:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit grid_model to the data\n",
    "grid_model_result = grid_model.fit(rescaledX_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))\n",
    "\n",
    "# Extract the best model and evaluate it on the test set\n",
    "best_model = grid_model_result.best_estimator_\n",
    "print(\"Accuracy of logistic regression classifier: \", best_model.score(rescaledX_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "201ab1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "513786bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create and fit an XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    reg_alpha=1.0,   # L1 regularization strength\n",
    "    reg_lambda=1.0   # L2 regularization strength\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7449a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8566a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
